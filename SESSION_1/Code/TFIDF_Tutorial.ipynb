{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. TF-IDF Tutorial\n",
    "- TF-IDF with a context d in D (corpus):\n",
    "\n",
    "$r_d = [tf-idf(w_1, d, D), tf-idf(w_2, d, D), ..., tf-idf(w_{|V|}, d, D)]$\n",
    "\n",
    "with, $r_d \\in R^{|V|}$ is a vector $|V|$ dims and $V = {w_i}$ is a dictionary (all words appear in $D$) respect to $D$\n",
    "\n",
    "- Inside:\n",
    "\n",
    "$tf-idf(w_i, d, D) = tf(w_i, d) * idf(w_i, D)$\n",
    "\n",
    "with,\n",
    "\n",
    "$tf(w_i, d) = \\dfrac{f(w_i, d)}{max(f(w_j, d): w_j \\in V)}$\n",
    "\n",
    "$idf(w_i, D) = log_{10}^{\\dfrac{|D|}{|d' \\in D: w_i \\in d'|}}$\n",
    "\n",
    "- Identify dictionary V:\n",
    "\n",
    "  - With each context $d$ in $D$:\n",
    "    - Separate d to some word by punctuation, then collect $W_d$\n",
    "    - Delete stop words from $W_d$\n",
    "    - Convert word to original (stemming), then collect $W_d$\n",
    "  - Finally:\n",
    "    $V = $ Intersection of $W_d$ with $d \\in D$\n",
    "## 0.1. Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Path\n",
    "import os\n",
    "# Other lib\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'science', 'is', 'the', 'sexiest', 'job', 'of', 'the', '21st', 'century']\n",
      "['machine', 'learning', 'is', 'the', 'key', 'for', 'data', 'science']\n",
      "{'learning', 'the', 'science', '21st', 'data', 'job', 'century', 'machine', 'for', 'key', 'of', 'is', 'sexiest'}\n"
     ]
    }
   ],
   "source": [
    "# Init data\n",
    "sentence_1 = \"Data Science is the sexiest job of the 21st century\"\n",
    "sentence_2 = \"Machine Learning is the key for Data Science\"\n",
    "\n",
    "# Process data \n",
    "sentence_1, sentence_2 = sentence_1.lower().split(), sentence_2.lower().split()\n",
    "sentence_1n2 = set(sentence_1).union(sentence_2)\n",
    "\n",
    "print(sentence_1, sentence_2, sentence_1n2, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'science', 'sexiest', 'job', '21st', 'century']\n",
      "['machine', 'learning', 'key', 'data', 'science']\n",
      "['learning', 'science', '21st', 'data', 'job', 'century', 'machine', 'key', 'sexiest']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/charles/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download file stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')         \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Filter sentence by stopwords with module ntlk\n",
    "ft_sentence_1 = [word for word in sentence_1 if word not in stop_words]\n",
    "ft_sentence_2 = [word for word in sentence_2 if word not in stop_words]\n",
    "ft_sentence_1n2 = [word for word in sentence_1n2 if word not in stop_words]\n",
    "\n",
    "print(ft_sentence_1, ft_sentence_2, ft_sentence_1n2, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning</th>\n",
       "      <th>science</th>\n",
       "      <th>21st</th>\n",
       "      <th>data</th>\n",
       "      <th>job</th>\n",
       "      <th>century</th>\n",
       "      <th>machine</th>\n",
       "      <th>key</th>\n",
       "      <th>sexiest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning  science  21st  data  job  century  machine  key  sexiest\n",
       "0         0        1     1     1    1        1        0    0        1\n",
       "1         1        1     0     1    0        0        1    1        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict.fromkeys: create  dictionary with keys from iterable and values set to value.\n",
    "dictA, dictB = dict.fromkeys(ft_sentence_1n2, 0), dict.fromkeys(ft_sentence_1n2, 0)\n",
    "# Check element for each sentence \n",
    "for _ in ft_sentence_1:\n",
    "    dictA[_] = dictA.get(_, 0) + 1 \n",
    "for _ in ft_sentence_2:\n",
    "    dictB[_] = dictB.get(_, 0) + 1 \n",
    "\n",
    "# Create DF\n",
    "df = pd.DataFrame([dictA, dictB])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning</th>\n",
       "      <th>science</th>\n",
       "      <th>21st</th>\n",
       "      <th>data</th>\n",
       "      <th>job</th>\n",
       "      <th>century</th>\n",
       "      <th>machine</th>\n",
       "      <th>key</th>\n",
       "      <th>sexiest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning  science     21st  data      job  century  machine      key  \\\n",
       "0   0.00000      0.0  0.30103   0.0  0.30103  0.30103  0.00000  0.00000   \n",
       "1   0.30103      0.0  0.00000   0.0  0.00000  0.00000  0.30103  0.30103   \n",
       "\n",
       "   sexiest  \n",
       "0  0.30103  \n",
       "1  0.00000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute TF-IDF\n",
    "def compute_tfidf(word_dict):\n",
    "    # Compute TF \n",
    "    def compute_tf(word_dict):\n",
    "        tf_dict = {}\n",
    "        for key, val in word_dict.items():\n",
    "            tf_dict[key] = word_dict[key] / max(word_dict.values())\n",
    "        return tf_dict\n",
    "    \n",
    "    # Compute IDF \n",
    "    def compute_idf(word_dict, data = df):\n",
    "        # |D| is number of elements D (chose dict)\n",
    "        N = data.shape[0]\n",
    "        idf_dict = {}\n",
    "        \n",
    "        for key, val in word_dict.items():\n",
    "            # Number of documents where the term t appears \n",
    "            val = np.sum(data[key] != 0)\n",
    "            # If the term is not in the corpus, this will lead to a division-by-zero, then adjust the denominator +1 \n",
    "            idf_dict[key] = math.log10(N / val)\n",
    "        return idf_dict   \n",
    "    \n",
    "    # Compute TF-IDF\n",
    "    tf_dict, idf_dict, tfidf_dict = compute_tf(word_dict), compute_idf(word_dict), {}\n",
    "    for key_tf, val_tf in tf_dict.items():\n",
    "        for key_idf, val_idf in idf_dict.items():\n",
    "            if key_idf == key_tf:\n",
    "                tfidf_dict[key_tf] = val_tf * val_idf\n",
    "    return tfidf_dict\n",
    "\n",
    "# Convert DF with TF-IDF\n",
    "df = pd.DataFrame([compute_tfidf(dictA), compute_tfidf(dictB)])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3. Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.4466561618018052\n",
      "  (0, 0)\t0.4466561618018052\n",
      "  (0, 3)\t0.4466561618018052\n",
      "  (0, 8)\t0.4466561618018052\n",
      "  (0, 7)\t0.31779953783628945\n",
      "  (0, 2)\t0.31779953783628945\n",
      "  (1, 4)\t0.4992213265230509\n",
      "  (1, 5)\t0.4992213265230509\n",
      "  (1, 6)\t0.4992213265230509\n",
      "  (1, 7)\t0.35520008546852583\n",
      "  (1, 2)\t0.35520008546852583\n"
     ]
    }
   ],
   "source": [
    "# Import sklearn tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorize = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Init data \n",
    "first_sentence = \"Data Science is the sexiest job of the 21st century\"\n",
    "second_sentence = \"Machine Learning is the key for Data Science\"\n",
    "\n",
    "# fit & transform data \n",
    "process_text = vectorize.fit_transform([first_sentence, second_sentence])\n",
    "print(process_text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "618af10fdd433c84be79e5d9cef7a85d74ad68be7e2e9dd9461a47b527f16862"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
